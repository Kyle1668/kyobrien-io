<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kyle O'Brien - AI Safety Researcher</title>

    <!-- SEO Meta Description -->
    <meta name="description" content="AI Safety Researcher at EleutherAI and UK AISI. Studying pre-training safety interventions, interpretability, and machine learning robustness.">
    <meta name="keywords" content="Kyle O'Brien, AI safety, machine learning, interpretability, EleutherAI, UK AISI, ERA Cambridge, activation steering, adversarial robustness, machine unlearning">
    <meta name="author" content="Kyle O'Brien">
    <link rel="canonical" href="https://www.kyobrien.io">

    <!-- Open Graph Meta Tags -->
    <meta property="og:title" content="Kyle O'Brien - AI Safety Researcher">
    <meta property="og:description" content="Working on understanding the internal mechanisms of advanced machine learning models to improve AI safety.">
    <meta property="og:image" content="https://www.kyobrien.io/images/profile.jpg">
    <meta property="og:url" content="https://www.kyobrien.io">
    <meta property="og:type" content="website">
    <meta property="og:site_name" content="Kyle O'Brien">

    <!-- Twitter Card Meta Tags -->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Kyle O'Brien - AI Safety Researcher">
    <meta name="twitter:description" content="Working on understanding the internal mechanisms of advanced machine learning models to improve AI safety.">
    <meta name="twitter:image" content="https://www.kyobrien.io/images/profile.jpg">
    <meta name="twitter:site" content="@KyleDevinOBrien">

    <link rel="stylesheet" href="styles.css">
    <link rel="icon" type="image/png" href="images/favicon.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <div class="container">
        <header>
            <img src="images/profile.jpg" alt="Kyle O'Brien" class="profile-image">
            <h1>Kyle O'Brien</h1>
            <p class="subtitle">Trying to understand the minds on our computers</p>

            <nav>
                <a href="https://twitter.com/KyleDevinOBrien" class="nav-link" target="_blank">
                    <svg viewBox="0 0 24 24" class="social-icon">
                        <path fill="currentColor" d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/>
                    </svg>
                    <span>Twitter</span>
                </a>
                <span class="nav-separator">|</span>
                <a href="https://github.com/kyle1668" class="nav-link" target="_blank">
                    <svg viewBox="0 0 98 96" xmlns="http://www.w3.org/2000/svg" class="social-icon">
                        <path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z" fill="currentColor"/>
                    </svg>
                    <span>GitHub</span>
                </a>
                <span class="nav-separator">|</span>
                <a href="https://www.linkedin.com/in/kyle1668/" class="nav-link" target="_blank">
                    <svg viewBox="0 0 24 24" class="social-icon">
                        <path fill="currentColor" d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
                    </svg>
                    <span>LinkedIn</span>
                </a>
                <span class="nav-separator">|</span>
                <a href="https://scholar.google.com/citations?user=YOUR_ID" class="nav-link" target="_blank">
                    <svg viewBox="0 0 24 24" class="social-icon">
                        <path fill="currentColor" d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"/>
                    </svg>
                    <span>Scholar</span>
                </a>
                <span class="nav-separator">|</span>
                <a href="https://huggingface.co/kyle1668" class="nav-link" target="_blank">
                    <svg viewBox="0 0 24 24" class="social-icon">
                        <path fill="currentColor" d="M12.958 4.042a8.5 8.5 0 0 0-8.916 8.916c0 4.688 3.813 8.5 8.5 8.5a8.432 8.432 0 0 0 3.744-.875c.281.156.646.292 1.104.292c1.271 0 2.084-1.167 2.084-2.292c0-.458-.136-.813-.292-.969a8.44 8.44 0 0 0 .875-3.74c.417-4.687-3.813-8.5-8.5-8.5zm-4.5 9.167c-.552 0-1-.448-1-1s.448-1 1-1s1 .448 1 1s-.448 1-1 1zm7 0c-.552 0-1-.448-1-1s.448-1 1-1s1 .448 1 1s-.448 1-1 1z"/>
                    </svg>
                    <span>HuggingFace</span>
                </a>
            </nav>
        </header>

        <main>
            <section id="current">
                <h2>Current Work</h2>
                <div class="position-card">
                    <p>I'm currently working at <a href="https://www.eleuther.ai/" target="_blank"><strong>EleutherAI</strong></a> through Spring 2025, where I'm studying pre-training safety interventions with the <a href="https://www.aisi.gov.uk/" target="_blank"><strong>UK AI Security Institute</strong></a>. I'm also an AI Safety Research Fellow with <a href="https://erafellowship.org/fellowship" target="_blank"><strong>ERA Cambridge</strong></a>.</p>
                    <p class="highlight-box">I'm seeking research opportunities starting Fall 2025.</p>
                </div>
            </section>

            <section id="direction">
                <h2>Research Direction</h2>
                <p>
                    My research focuses on understanding the internal mechanisms of advanced machine learning models. I'm passionate about developing lightweight safety interventions that can be integrated directly into the training process.
                </p>
                <p>
                    My work spans several key areas including <strong>activation steering</strong>, <strong>adversarial robustness</strong>, and <strong>machine unlearning</strong>. I believe that by deeply understanding how models process and store information, we can build safer and more reliable AI systems.
                </p>
            </section>

            <section id="publications">
                <h2>Selected Publications</h2>
                <div class="publications-list">
                    <div class="publication-item">
                        <h3><a href="https://arxiv.org/abs/2508.06601" target="_blank">Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs</a></h3>
                        <p class="authors">Kyle O'Brien, Stephen Casper, Quentin Anthony, Tomek Korbak, Robert Kirk, Xander Davies, Ishan Mishra, Geoffrey Irving, Yarin Gal, Stella Biderman</p>
                        <p class="venue">arXiv preprint, 2025</p>
                        <img src="images/deep_ignorance_fig.png" alt="Deep Ignorance figure" class="publication-figure">
                        <blockquote class="abstract">We investigate whether filtering dual-use topics from training data can serve as a tamper-resistant safeguard for open-weight LLMs. Our multi-stage data filtering pipeline demonstrates substantial resistance to adversarial fine-tuning on up to 10,000 steps and 300M tokens of biothreat-related text, outperforming existing post-training baselines by over an order of magnitude, with no degradation to unrelated capabilities.</blockquote>
                    </div>

                    <div class="publication-item">
                        <h3><a href="https://arxiv.org/abs/2411.11296" target="_blank">Steering Language Model Refusal with Sparse Autoencoders</a></h3>
                        <p class="authors">Kyle O'Brien, D. Majercak, Xavier Fernandes, Richard Edgar, Jingya Chen, Harsha Nori, Dean Carignan, Eric Horvitz, Forough Poursabzi-Sangdeh</p>
                        <p class="venue">ICML 2025 Workshop on Actionable Interpretability</p>
                        <img src="images/steering_sae_fig.png" alt="Steering SAE figure" class="publication-figure">
                        <blockquote class="abstract">We explore steering model activations at inference time via amplifying sparse autoencoder (SAE) features that mediate refusal. While feature steering successfully improves robustness against jailbreak attempts, we discover a fundamental tension between SAE steering-based safety improvements and general model capabilities, with systematic degradation of performance across benchmark tasks.</blockquote>
                    </div>

                    <div class="publication-item">
                        <h3><a href="https://arxiv.org/abs/2407.06483" target="_blank">Composable Interventions for Language Models</a></h3>
                        <p class="authors">Arinbj√∂rn Kolbeinsson, Kyle O'Brien, Tianjin Huang, Shanghua Gao, Shiwei Liu, Jonathan Richard Schwarz, Anurag Vaidya, Faisal Mahmood, M. Zitnik, Tianlong Chen, Thomas Hartvigsen</p>
                        <p class="venue">International Conference on Learning Representations (ICLR), 2024</p>
                        <img src="images/composable_fig.png" alt="Composable Interventions figure" class="publication-figure">
                        <blockquote class="abstract">We introduce composable interventions, a framework to study the effects of using multiple interventions on the same language models. Using our framework, we conduct extensive experiments composing popular methods from Knowledge Editing, Model Compression, and Machine Unlearning, revealing complex interaction patterns when interventions are applied sequentially.</blockquote>
                    </div>

                    <div class="publication-item">
                        <h3><a href="https://arxiv.org/abs/2406.17746" target="_blank">Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon</a></h3>
                        <p class="authors">USVSN Sai Prashanth, Alvin Deng, Kyle O'Brien, V Jyothir S, Mohammad Aflah Khan, Jaydeep Borkar, Christopher A. Choquette-Choo, Jacob Ray Fuehne, Stella Biderman, Tracy Ke, Katherine Lee, Naomi Saphra</p>
                        <p class="venue">International Conference on Learning Representations (ICLR), 2024</p>
                        <img src="images/recite_fig.png" alt="Recite, Reconstruct, Recollect figure" class="publication-figure">
                        <blockquote class="abstract">We model memorization as a multifaceted phenomenon, introducing a taxonomy that breaks it into recitation (of highly duplicated sequences), reconstruction (of inherently predictable sequences), and recollection (of sequences that are neither). We demonstrate the taxonomy's usefulness by constructing a predictive model showing different factors influence memorization likelihood across categories.</blockquote>
                    </div>

                    <div class="publication-item">
                        <h3><a href="https://arxiv.org/abs/2402.08225" target="_blank">Improving Black-box Robustness with In-Context Rewriting</a></h3>
                        <p class="authors">Kyle O'Brien, Nathan Ng, Isha Puri, Jorge Mendez, Hamid Palangi, Yoon Kim, Marzyeh Ghassemi, Tom Hartvigsen</p>
                        <p class="venue">Transactions on Machine Learning Research (TMLR), 2024</p>
                        <img src="images/icr_fig.png" alt="In-Context Rewriting figure" class="publication-figure">
                        <blockquote class="abstract">We propose LLM-TTA, which uses LLM-generated augmentations for test-time augmentation to improve model robustness on out-of-distribution inputs. Our In-Context Rewriting method rewrites inputs to match in-distribution exemplars, outperforming conventional augmentation functions for BERT and T5 across sentiment, toxicity, and news classification tasks.</blockquote>
                    </div>

                    <div class="publication-item">
                        <h3><a href="https://arxiv.org/abs/2304.01373" target="_blank">Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling</a></h3>
                        <p class="authors">Stella Biderman, Hailey Schoelkopf, Quentin Anthony, Herbie Bradley, Kyle O'Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, Aviya Skowron, Lintang Sutawika, Oskar van der Wal</p>
                        <p class="venue">International Conference on Machine Learning (ICML), 2023</p>
                        <blockquote class="abstract">We introduce Pythia, a suite of 16 LLMs ranging from 70M to 12B parameters, all trained on public data in the exact same order. We provide 154 checkpoints per model alongside tools to reconstruct training dataloaders, facilitating research in memorization, few-shot performance, and bias reduction through this highly controlled setup.</blockquote>
                    </div>
                </div>
            </section>

            <section id="contact">
                <h2>Get in Touch</h2>
                <div class="contact-box">
                    <p>
                        I'm always happy to meet people interested in my research, potential collaborations, or career advice. Feel free to reach out!
                    </p>
                    <p class="email">
                        <strong>Email:</strong> <a href="mailto:kyledevinobrien1@gmail.com">kyledevinobrien1@gmail.com</a>
                    </p>
                </div>
            </section>
        </main>

        <footer>
            <p>&copy; 2024 Kyle O'Brien. All rights reserved.</p>
        </footer>
    </div>
</body>
</html>